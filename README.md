# NLPstudy_TAVE

TAVE 14기 활동하며 NLP 공부한 과정을 기록하는 스터디입니다.

[멤버]
정현정, 지상은, 홍수인, 홍진화

[기간] 
1회차 : 09.14_RNN&LSTM
TAVE 스터디 기획안
팀장
홍진화
팀 구성원
지상은, 홍수인, 정현정, 정성윤
팀 이름
강북치기박치기


스터디 소개 
설명
1. 자연어처리 + NLP 스터디
모델 : RNN LSTM Transformer BERT T5 GPT
허깅페이스 라이브러리 활용 프로젝트

2. LLM 스터디
랭체인, RAG, Re-Act, 리트리벌
llama3.1, gemma, GPT api

위 내용들을 기반으로 논문+코드예제를 통해 내용 학습 및 git 포트폴리오 준비

진행시간
[필수 스터디-대면] 토요일 14시~16시
[추가 스터디- 비대면] 화요일 19시~21시(10월 둘째주만 월요일인 10월 7일 20시~22시 진행)

진행방식(필수는 *)
[과제*] 관련 유튜브 영상 시청
[과제*] 논문 읽고 정리해오기(github 포폴로 사용 예정)
[스터디*] 전체적인 플로우 발표
[스터디*] 공부하면서 이해가 안가는 내용 질의응답(github에 정리한 내용 업데이트
[과제] 예제 코드 따라치고 주석달기(optional)
https://wikidocs.net/217687
https://wikidocs.net/156986
https://github.com/deepseasw/bert-naver-movie-review?tab=readme-ov-file
-> 위 예제는 샘플들이며, 추후 변경 예정
목표
NLP 허깅페이스 모델 활용
참고자료
https://asidefine.tistory.com/180
작업환경
(사용 툴
또는 언어)
Python(Pytorch)

	
교재 소개
교재 이름 및 내용
논문


세부 계획


주차별 계획
0주차


만남의 장
1주차
1). RNN, LSTM(9/14, 대면)
RNN, LSTM은 논문을 읽지는 않고, 교육자료 활용할 예정
https://www.fit.vut.cz/research/group/speech/public/publi/2010/mikolov_interspeech2010_IS100722.pdf
https://arxiv.org/abs/1402.1128


2주차
2). transformer(9/21, 대면)
https://arxiv.org/pdf/1706.03762
3주차
3). BERT(9/24, 비대면)
https://arxiv.org/pdf/1810.04805
4). GPT(9/28, 대면)
https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf
4주차
5). T5(10/1, 비대면)
https://arxiv.org/pdf/1910.10683
6). GPT-3(10/5, 대면)
https://arxiv.org/pdf/1910.10683
5주차
7). prompt engineering(10/7, 비대면)
https://arxiv.org/pdf/2312.16171
claude의 system prompt가 어떻게 이루어져있는지 보기
https://docs.anthropic.com/en/release-notes/system-prompts#july-12th-2024
8). Hugging face 사용(10/12, 대면)
실습
6주차
9). Re-Act(10/15, 비대면)
실습
10). RAG(10/19, 대면)
실습
7주차
내용 복습 & 부족한 내용(optional)


